# Azure AI Gateway v2

A multi-region Azure AI Gateway implementation using Azure API Management (APIM) with priority-based backend pools, circuit breaker patterns, and comprehensive monitoring for Azure OpenAI deployments.

## ğŸ—ï¸ Architecture Overview

This solution creates a resilient, multi-region Azure AI Gateway that:

- **Multi-Region Resilience**: Deploys Azure AI Foundry accounts across 3 regions with automatic failover
- **Priority-Based Routing**: Routes requests to regional backends based on configurable priority (1â†’2â†’3)
- **Circuit Breaker Pattern**: Opens circuit for 10 seconds on a single 429 error, preventing cascading failures
- **Dual API Support**: Supports both Azure OpenAI native format (`/openai/deployments/*`) and OpenAI v1 compatible format (`/v1/*`)
- **Managed Identity Authentication**: Uses Azure managed identity for secure, keyless authentication to AI Foundry
- **Comprehensive Monitoring**: Application Insights integration with token usage tracking

### Architecture Diagram

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                          API Consumer                            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                â”‚
                                â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   Azure API Management (APIM)                    â”‚
â”‚                       (West Europe)                              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚  APIs:                                                    â”‚  â”‚
â”‚  â”‚  â€¢ /openai/deployments/* (Azure OpenAI format)           â”‚  â”‚
â”‚  â”‚  â€¢ /v1/* (OpenAI compatible format)                      â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚  Backend Pools (per model):                              â”‚  â”‚
â”‚  â”‚  â€¢ pool-gpt-4o-mini-2024-dot-07-dot-18                   â”‚  â”‚
â”‚  â”‚    - Priority 1: West Europe                             â”‚  â”‚
â”‚  â”‚    - Priority 2: North Europe                            â”‚  â”‚
â”‚  â”‚    - Priority 3: Sweden Central                          â”‚  â”‚
â”‚  â”‚  Circuit Breaker: 1x 429 â†’ 10s timeout                   â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â”‚                       â”‚                       â”‚
        â–¼                       â–¼                       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ AI Foundry    â”‚      â”‚ AI Foundry    â”‚      â”‚ AI Foundry    â”‚
â”‚ West Europe   â”‚      â”‚ North Europe  â”‚      â”‚ Sweden Centralâ”‚
â”‚ (Priority 1)  â”‚      â”‚ (Priority 2)  â”‚      â”‚ (Priority 3)  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â”‚                       â”‚                       â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                â”‚
                                â–¼
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚ Azure Monitor         â”‚
                    â”‚ â€¢ Log Analytics       â”‚
                    â”‚ â€¢ Application Insightsâ”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸš€ Features

### Multi-Region Deployment
- AI Foundry accounts deployed across 3 configurable regions
- Each region hosts model deployments with the same model versions
- Regional endpoints automatically configured as APIM backends

### Backend Pool Configuration
- One backend pool per unique model deployment name
- Backends organized by strict priority order (1, 2, 3)
- Circuit breaker with single 429 threshold and 10-second trip duration

### Authentication & Security
- Single user-assigned managed identity for APIM
- Managed identity granted `Cognitive Services OpenAI User` and `Azure AI Developer` roles
- All authentication handled in APIM policies (no API keys stored)

### Monitoring & Observability
- Application Insights for telemetry and diagnostics
- Log Analytics workspace for log aggregation
- Azure OpenAI token metrics emitted for usage tracking
- Request/response logging with deployment tracking

## ğŸ“‹ Prerequisites

- Azure subscription with sufficient quota for:
  - API Management StandardV2 SKU
  - Azure AI Foundry (Cognitive Services) in 3 regions
  - Log Analytics workspace
- Azure CLI installed ([Install guide](https://docs.microsoft.com/cli/azure/install-azure-cli))
- PowerShell 7+ (for deployment script)
- Appropriate Azure permissions:
  - Contributor role on target subscription/resource group
  - User Access Administrator (for RBAC assignments)

## ğŸ› ï¸ Deployment

### 1. Configure Parameters

Edit `infra/main.acc.parameters.bicepparam`:

```bicep
using 'main.bicep'

param environment = 'acc'
param suffix = 'genaishared'
param rgLocation = 'westeurope'
param apimPublisherEmail = 'your-email@example.com'
param apimPublisherName = 'Your Organization'
param apimSku = 'StandardV2'

param openAILocations = [
  {
    name: 'westeurope'
    abbreviation: 'weu'
    deployments: [
      {
        deploymentName: 'gpt-4o-mini-2024-07-18-standard'
        name: 'gpt-4o-mini'
        version: '2024-07-18'
        format: 'OpenAI'
        skuName: 'Standard'
        skuCapacity: 10
        priority: 1
      }
    ]
  }
  {
    name: 'northeurope'
    abbreviation: 'neu'
    deployments: [
      {
        deploymentName: 'gpt-4o-mini-2024-07-18-standard'
        name: 'gpt-4o-mini'
        version: '2024-07-18'
        format: 'OpenAI'
        skuName: 'Standard'
        skuCapacity: 10
        priority: 2
      }
    ]
  }
  {
    name: 'swedencentral'
    abbreviation: 'swc'
    deployments: [
      {
        deploymentName: 'gpt-4o-mini-2024-07-18-standard'
        name: 'gpt-4o-mini'
        version: '2024-07-18'
        format: 'OpenAI'
        skuName: 'Standard'
        skuCapacity: 10
        priority: 3
      }
    ]
  }
]
```

### 2. Update Resource Group Configuration

Edit `infra/resourcegroup.config.json`:

```json
{
  "resourceGroupNames": ["rg-ai-gateway-acc"],
  "tags": {
    "environment": "acceptance",
    "project": "ai-gateway",
    "costCenter": "IT"
  }
}
```

### 3. Run Deployment

```powershell
# Login to Azure
az login

# Deploy infrastructure (dry run)
.\deploy.ps1 -WhatIf

# Deploy infrastructure
.\deploy.ps1

# Deploy to specific subscription
.\deploy.ps1 -SubscriptionId "12345678-1234-1234-1234-123456789012"
```

### 4. Verify Deployment

The deployment script outputs key information:

```
Deployment Outputs:
==================
APIM Gateway URL: https://apim-acc-genaishared-xxxxx.azure-api.net
APIM Name: apim-acc-genaishared-xxxxx
Managed Identity Client ID: xxxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx
Log Analytics Workspace ID: /subscriptions/.../workspaces/law-acc-genaishared
```

## ğŸ§ª Testing

### Setup Test Environment

```powershell
# Create and activate virtual environment
python -m venv .venv
.\.venv\Scripts\Activate.ps1

# Install test dependencies
pip install -r tests/requirements.txt

# Authenticate with Azure
az login
```

### Run Tests

```powershell
# Test Azure OpenAI native format
cd tests
python test_azure_openai.py

# Test OpenAI v1 compatible format
python test_openai_v1.py

# Test models endpoint
python test_models_v1.py
```

See [tests/README.md](tests/README.md) for detailed testing documentation.

## ğŸ“ Project Structure

```
ai-gw-v2/
â”œâ”€â”€ deploy.ps1                          # Deployment automation script
â”œâ”€â”€ plan.md                             # Detailed deployment plan
â”œâ”€â”€ README.md                           # This file
â”‚
â”œâ”€â”€ infra/                              # Infrastructure as Code
â”‚   â”œâ”€â”€ main.bicep                      # Main orchestration template
â”‚   â”œâ”€â”€ main.acc.parameters.bicepparam  # Environment parameters
â”‚   â”œâ”€â”€ main.json                       # Compiled ARM template
â”‚   â”œâ”€â”€ resourcegroup.config.json       # Resource group configuration
â”‚   â”‚
â”‚   â””â”€â”€ modules/                        # Bicep modules
â”‚       â”œâ”€â”€ ai-foundry.bicep           # AI Foundry account & project
â”‚       â”œâ”€â”€ ai-foundry-rbac.bicep      # RBAC role assignments
â”‚       â”œâ”€â”€ apim.bicep                 # API Management service
â”‚       â”œâ”€â”€ apim-backend-pools.bicep   # Backend pool configuration
â”‚       â”œâ”€â”€ apim-config.bicep          # Named values configuration
â”‚       â”œâ”€â”€ apim-policies.bicep        # Policy attachment
â”‚       â”œâ”€â”€ app-insights.bicep         # Application Insights
â”‚       â”œâ”€â”€ log-analytics.bicep        # Log Analytics workspace
â”‚       â””â”€â”€ model-deployments.bicep    # Model deployments & backends
â”‚
â”œâ”€â”€ apim-policies/                      # APIM policy definitions
â”‚   â”œâ”€â”€ aoai-policy.xml                # Azure OpenAI format policy
â”‚   â””â”€â”€ oaiv1-policy.xml               # OpenAI v1 format policy
â”‚
â”œâ”€â”€ openapi/                            # OpenAPI specifications
â”‚   â”œâ”€â”€ azure-openai-2024-02-01.json   # Azure OpenAI API spec
â”‚   â””â”€â”€ openai-v1.json                 # OpenAI v1 API spec
â”‚
â”œâ”€â”€ queries/                            # KQL queries
â”‚   â””â”€â”€ token-metrics.kql              # Token usage metrics
â”‚
â””â”€â”€ tests/                              # Test scripts
    â”œâ”€â”€ README.md                       # Testing documentation
    â”œâ”€â”€ requirements.txt                # Test dependencies
    â”œâ”€â”€ test_azure_openai.py           # Azure OpenAI format tests
    â”œâ”€â”€ test_models_v1.py              # Models endpoint tests
    â””â”€â”€ test_openai_v1.py              # OpenAI v1 format tests
```

## ğŸ”§ Configuration

### Backend Pool Settings

Backend pools are configured in `modules/apim-backend-pools.bicep`:

- **Circuit Breaker**: Single 429 response opens circuit
- **Trip Duration**: 10 seconds
- **Priority Routing**: Strict priority-based (1â†’2â†’3)
- **Health Checks**: Automatic backend health monitoring

### APIM Policy Features

Both `aoai-policy.xml` and `oaiv1-policy.xml` implement:

1. **Managed Identity Authentication**: Automatic token acquisition for Cognitive Services
2. **Dynamic Backend Selection**: Routes to correct backend pool based on deployment/model name
3. **Streaming Support**: Injects `stream_options.include_usage: true` for token tracking
4. **Token Metrics**: Emits usage metrics to Application Insights
5. **Retry Logic**: 2 retries with 1-second intervals on 429 errors

### Named Values

APIM named values (configured in `modules/apim-config.bicep`):

- `managed-identity-client-id`: Client ID of the APIM managed identity

## ğŸ“Š Monitoring

### Application Insights

Token usage metrics are automatically captured:
- Prompt tokens
- Completion tokens
- Total tokens
- Model deployment name
- Request ID
- Streaming flag

### Query Usage Metrics

Use the provided KQL query (`queries/token-metrics.kql`) in Log Analytics:

```kql
customMetrics
| where name startswith "AzureOpenAI"
| extend Deployment = tostring(customDimensions["Deployment"])
| extend Streaming = tostring(customDimensions["Streaming"])
| summarize 
    TotalRequests = count(),
    AvgPromptTokens = avg(valueMax),
    AvgCompletionTokens = avg(valueMax)
    by Deployment, Streaming
```

## ğŸ”’ Security Considerations

1. **No API Keys**: All authentication uses Azure managed identity
2. **RBAC**: Minimal permissions granted (Cognitive Services OpenAI User, Azure AI Developer)
3. **Project-Level Scoping**: RBAC assignments scoped to individual AI Foundry projects
4. **Network Security**: Public access enabled (configure VNet integration if needed)
5. **Policy-Based Auth**: Authentication logic centralized in APIM policies

## ğŸš¦ Rate Limiting & Circuit Breaking

### Circuit Breaker Behavior

1. **Normal Operation**: Requests route to Priority 1 backend
2. **Single 429 Error**: Circuit opens, backend excluded for 10 seconds
3. **Automatic Failover**: Traffic shifts to Priority 2 backend
4. **Auto-Recovery**: After 10 seconds, circuit closes and Priority 1 is retried

### Retry Logic

- **Retry Count**: 2 retries
- **Retry Interval**: 1 second
- **First Fast Retry**: Enabled
- **Retry Condition**: HTTP 429 (Too Many Requests)

## ğŸ› Troubleshooting

### Check Backend Health

```powershell
# List all backends in APIM
az apim backend list --resource-group rg-ai-gateway-acc --service-name apim-acc-genaishared-xxxxx

# Show backend pool configuration
az apim backend show --resource-group rg-ai-gateway-acc --service-name apim-acc-genaishared-xxxxx --backend-id pool-gpt-4o-mini-2024-dot-07-dot-18
```

### View Logs

```powershell
# Query Application Insights logs
az monitor app-insights query --app <app-insights-id> --analytics-query "requests | where timestamp > ago(1h)"
```

### Common Issues

**Issue**: 401 Unauthorized errors
- **Solution**: Verify managed identity has correct RBAC roles on AI Foundry projects

**Issue**: 404 Backend not found
- **Solution**: Ensure deployment name matches backend pool name (dots replaced with `-dot-`)

**Issue**: 429 errors not triggering circuit breaker
- **Solution**: Check backend pool configuration has correct trip threshold (should be 1)

## ğŸ“š Additional Resources

- [Azure API Management Documentation](https://docs.microsoft.com/azure/api-management/)
- [Azure OpenAI Service Documentation](https://docs.microsoft.com/azure/cognitive-services/openai/)
- [Azure AI Foundry Documentation](https://docs.microsoft.com/azure/ai-services/ai-foundry/)
- [Backend Circuit Breaker Pattern](https://docs.microsoft.com/azure/api-management/backends)

## ğŸ“ License

This project is licensed under the MIT License.

## ğŸ¤ Contributing

Contributions are welcome! Please open an issue or submit a pull request.

## ğŸ“§ Support

For issues and questions:
1. Check the [Troubleshooting](#-troubleshooting) section
2. Review Application Insights logs
3. Open an issue in this repository
